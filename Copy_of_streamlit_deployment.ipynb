{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of streamlit deployment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46i2YHdouLLD"
      },
      "source": [
        "# Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj6Fu5dz-xa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9433df1-99db-4a24-8eb5-078fc6df8057"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.7/dist-packages (0.79.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.18.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (20.9)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
            "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.12.4)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.0)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.6.1)\n",
            "Requirement already satisfied: watchdog; platform_system != \"Darwin\" in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.1.14)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.0.0)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->streamlit) (1.15.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (54.1.2)\n",
            "Requirement already satisfied: ipykernel>=5.1.2; python_version >= \"3.4\" in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
            "Requirement already satisfied: jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (2.11.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython->streamlit) (4.0.5)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10.1->pydeck>=0.1.dev5->streamlit) (1.1.1)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython->streamlit) (3.0.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (1.0.18)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (22.0.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO3yQr-RxcSi",
        "outputId": "ddfe39f1-4929-4789-e181-ac2589104ff3"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.0.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1EePjSuTgZ"
      },
      "source": [
        "# Importing Libraries and Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S_AHYv0tZJ3"
      },
      "source": [
        "import streamlit as st  ## streamlit\n",
        "import pandas as pd  ## for data manipulation\n",
        "import pickle   ## For model loading \n",
        "import spacy  ## For NLP tasks \n",
        "import time\n",
        "\n",
        "from PIL import Image   ## For image\n",
        "from io import StringIO  ## for text input and output from the web app"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f35Irkfu-2t2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f4e838b-fdb8-493b-fa31-80e145ed5945"
      },
      "source": [
        "from keras.models import load_model\n",
        "# load model\n",
        "model = load_model('/content/my_model.h5')\n",
        "# summarize model.\n",
        "model.summary()\n",
        "# load dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_36 (Dense)             (None, 512)               51712     \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 6)                 3078      \n",
            "=================================================================\n",
            "Total params: 317,446\n",
            "Trainable params: 317,446\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RHv8ImVtp6A",
        "outputId": "d898da81-5b2f-4137-fc5e-e43dbf28c28e"
      },
      "source": [
        "# load the model from disk\n",
        "# Load model from file\n",
        "from sklearn.externals import joblib\n",
        "classifier = joblib.load(\"/content/pickle_nb.pkl\")\n",
        "classifier"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdsXpbx7ucZQ"
      },
      "source": [
        "# Streamlit App"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5JmExybuOFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e922d87-cc94-46bf-c85f-2c678dda9eee"
      },
      "source": [
        "# defining the function which will make the prediction using the data which the user inputs\n",
        "%%writefile app.py \n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "def welcome(): \n",
        "  return 'welcome all'\n",
        "\n",
        "# defining the function which will make the prediction using  \n",
        "# the data which the user inputs \n",
        "def prediction(tweet):\n",
        "  from keras.models import load_model\n",
        "  model = load_model('/content/sent_model.h5')\n",
        "  classifier = joblib.load(\"/content/pickle_nb.pkl\")\n",
        "  # Making predictions \n",
        "  \n",
        "  from keras.preprocessing.text import Tokenizer\n",
        "  from keras.preprocessing.sequence import pad_sequences\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  import numpy as np\n",
        "  #label_encoder = LabelEncoder()\n",
        "  text=np.array([tweet])\n",
        "  tk=Tokenizer(num_words=4000,lower=True,split=\" \")\n",
        "  tk.fit_on_texts(text)\n",
        "  prediction = model.predict_classes(pad_sequences(tk.texts_to_sequences(text),\n",
        "  maxlen=100))\n",
        "  if prediction == 0:\n",
        "    prediction = 'negative'\n",
        "    return prediction\n",
        "  elif prediction == 1:\n",
        "    prediction = 'neutral'\n",
        "    return prediction\n",
        "  else:\n",
        "    prediction = 'positive'\n",
        "    return prediction\n",
        "  text=np.array([tweet])\n",
        "  tk=Tokenizer(num_words=4000,lower=True,split=\" \")\n",
        "  tk.fit_on_texts(text)\n",
        "  prediction2 = classifier.predict_classes(pad_sequences(tk.texts_to_sequences(text),\n",
        "  maxlen=100))\n",
        "  if prediction2 == 0:\n",
        "    prediction2 = 'negative'\n",
        "    return prediction2\n",
        "  elif prediction2 == 1:\n",
        "    prediction2 = 'neutral'\n",
        "    return prediction2\n",
        "  else:\n",
        "    prediction2 = 'positive'\n",
        "    return prediction2\n",
        "# this is the main function in which we define our webpage \n",
        "def main():\n",
        "  import streamlit as st\n",
        "   # giving the webpage a title \n",
        "  st.title(\"Tweet Prediction\") \n",
        "  st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "  st.sidebar.title(\"Info\")\n",
        "\n",
        "  st.markdown(\"## Input Tweet in English\")\n",
        "  st.sidebar.markdown(\"This app uses artificial neural networks to predict the sentiment of a tweet \")\n",
        "\n",
        "    # front end elements of the web page \n",
        "  html_temp = \"\"\" \n",
        "  <div style =\"background-color:purple;padding:13px\"> \n",
        "  <h1 style =\"color:black;text-align:center;\">Streamlit Eagles Tweet App</h1> \n",
        "  </div> \n",
        "    \"\"\"\n",
        "    # display the front end aspect\n",
        "  st.markdown(html_temp, unsafe_allow_html = True) \n",
        "    # following lines create boxes in which user can enter data required to make prediction \n",
        "  Tweet = st.text_input(\"Tweet\")\n",
        "  result =\"\"\n",
        "        \n",
        "      # when 'Predict' is clicked, make the prediction and store it \n",
        "  if st.button(\"Predict\"): \n",
        "    result = prediction(Tweet) \n",
        "  st.success('The sentiment of the tweet is {}'.format(result))\n",
        "  # else:\n",
        "  #   result = prediction2(Tweet) \n",
        "  # st.success('The aspect of the tweet is {}'.format(result))\n",
        "\n",
        "data_path = (\"/content/clean_health_data.csv\")\n",
        "\n",
        "@st.cache()\n",
        "def load_data():\n",
        "    data = pd.read_csv(data_path)\n",
        "    data['tweet_created'] = pd.to_datetime(data['tweet_date'])\n",
        "    return data\n",
        "\n",
        "\n",
        "data = load_data()\n",
        "\n",
        "st.sidebar.subheader(\"Show random tweets\")\n",
        "random_tweet = st.sidebar.radio('Select the Sentiment',('positive','negative','neutral'))\n",
        "\n",
        "st.subheader(\"Here are some example of tweets according to your choice!\")\n",
        "st.markdown(\"1.\" + data.query(\"labels == @random_tweet\")[['tweet']].sample(n=1).iat[0,0])\n",
        "\n",
        "\n",
        "st.sidebar.markdown(\"### Choose Model\")\n",
        "select = st.sidebar.selectbox('Model Type',['ANN-Sentiment Model','Naive Bayes Model'])\n",
        "\n",
        "st.sidebar.markdown(\"### Number of tweets\")\n",
        "select = st.sidebar.selectbox('Visualization Type',['BarGraph','PieChart'])\n",
        "\n",
        "sentiment_count = data['labels'].value_counts()\n",
        "sentiment_count = pd.DataFrame({'Sentiments':sentiment_count.index,'Tweets':sentiment_count.values})\n",
        "\n",
        "def choose_model(model):\n",
        "        st.markdown(\"### Choose Model\")\n",
        "        if select=='ANN-Sentiment Model':\n",
        "            text=np.array([tweet])\n",
        "            tk=Tokenizer(num_words=4000,lower=True,split=\" \")\n",
        "            tk.fit_on_texts(text)\n",
        "            prediction = model.predict_classes(pad_sequences(tk.texts_to_sequences(text),\n",
        "            maxlen=100))\n",
        "            if prediction == 0:\n",
        "              prediction = 'negative'\n",
        "              return prediction\n",
        "            elif prediction == 1:\n",
        "              prediction = 'neutral'\n",
        "              return prediction\n",
        "            else:\n",
        "              prediction = 'positive'\n",
        "              return prediction \n",
        "        else:\n",
        "            text=np.array([tweet])\n",
        "            tk=Tokenizer(num_words=4000,lower=True,split=\" \")\n",
        "            tk.fit_on_texts(text)\n",
        "            prediction2 = classifier.predict_classes(pad_sequences(tk.texts_to_sequences(text),\n",
        "            maxlen=100))\n",
        "            if prediction2 == 0:\n",
        "              prediction2 = 'negative'\n",
        "              return prediction2\n",
        "            elif prediction2 == 1:\n",
        "              prediction2 = 'neutral'\n",
        "              return prediction2\n",
        "            else:\n",
        "              prediction2 = 'positive'\n",
        "              return prediction2 \n",
        "\n",
        "if st.sidebar.checkbox('Show',False,key='0'):\n",
        "    st.markdown(\"### No. of tweets by sentiments \")\n",
        "    if select=='BarGraph':\n",
        "        fig = px.bar(sentiment_count,x='Sentiments',y='Tweets',color='Tweets',height=500)\n",
        "        st.plotly_chart(fig)\n",
        "    else:\n",
        "        fig = px.pie(sentiment_count,values='Tweets',names='Sentiments')\n",
        "        st.plotly_chart(fig)\n",
        "\n",
        "# Word cloud\n",
        "st.sidebar.subheader(\"Word Cloud\")\n",
        "word_sentiment = st.sidebar.radio(\"Which Sentiment to Display?\", tuple(pd.unique(data[\"labels\"])))\n",
        "if st.sidebar.checkbox(\"Show\", False, key=\"6\"):\n",
        "    st.subheader(f\"Word Cloud for {word_sentiment.capitalize()} Sentiment\")\n",
        "    df = data[data[\"labels\"]==word_sentiment]\n",
        "    words = \" \".join(data[\"tweet\"])\n",
        "    processed_words = \" \".join([word for word in words.split() if \"http\" not in word and not word.startswith(\"@\") and word != \"RT\"])\n",
        "    wordcloud = WordCloud(stopwords=STOPWORDS, background_color=\"white\", width=800, height=640).generate(processed_words)\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    st.pyplot()\n",
        "\n",
        "if __name__=='__main__': \n",
        "    main()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSPUMEHYwqng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee513c8-3e50-400b-d40e-9a01fabd8bc4"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-23 06:28:51--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.197.133.26, 3.223.239.191, 34.226.165.133, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.197.133.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  19.2MB/s    in 0.7s    \n",
            "\n",
            "2021-03-23 06:28:52 (19.2 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6679q_6fwsJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3261f2b-486e-42e4-f894-f7c4e109f34b"
      },
      "source": [
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGCM2OjvxNit"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxwv00hdxedU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939b8293-c96b-4c0e-ffba-8309f163d350"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    'import sys, json; print(\"Execute the next cell and the go to the following URL: \" +json.load(sys.stdin)[\"tunnels\"][0][\"public_url\"])'"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execute the next cell and the go to the following URL: https://a4d5094e7edc.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYC-XlBr0Psh",
        "outputId": "17ac586b-dced-46e9-d615-9319912ade52"
      },
      "source": [
        "!streamlit run /content/app.py"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.27.206:8501\u001b[0m\n",
            "\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning:\n",
            "\n",
            "sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "\n",
            "2021-03-23 06:36:09.252 NumExpr defaulting to 2 threads.\n",
            "2021-03-23 06:36:44.262567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-03-23 06:36:45.453366: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-03-23 06:36:45.454355: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-23 06:36:45.465996: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-03-23 06:36:45.466042: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (8df0c17413d8): /proc/driver/nvidia/version does not exist\n",
            "2021-03-23 06:36:45.466394: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-03-23 06:36:45.466582: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
            "\n",
            "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "\n",
            "2021-03-23 06:36:45.594478: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-03-23 06:36:45.604219: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1999995000 Hz\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}